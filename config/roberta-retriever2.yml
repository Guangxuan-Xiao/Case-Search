title: roberta-retriever2-train
log_dir: ../log/
mode: train
use_wandb: False
seeds: [1, 2, 3, 4, 5]
data:
  path: ../data/origin
  num_workers: 12
  num_classes: 2
  query_seq_len: 256
  candidate_seq_len: 256
  augmentation: False
  label_type: retrieve2
model:
  type: cross
  encoder: ../models/chinese-roberta-wwm-ext
  dropout: 0.1
  device: "cuda:3"
  device_ids: [3]
  loss_fn: BCEWithLogitsLoss
  pooler: cls
  head: regression
optimizer:
  accumulation_steps: 1
  name: Adam
  lr: 0.00002
  scheduler: cos
train:
  batch_size: 32
  eval_batch_size: 100
  num_epochs: 3
