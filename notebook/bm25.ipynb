{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from gensim.summarization import bm25\n",
    "import jieba\n",
    "import numpy as np\n",
    "from summary import stopwords, split_sentence, unique_sentences\n",
    "from icecream import ic\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from icecream import ic\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/chinese-roberta-wwm-ext\")\n",
    "crime_pattern = re.compile(r'已构成(.*?)罪')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_query = \"2018年1月15日14时10分许，被告人莫新国酒后驾驶湘A×××××号小型轿车沿长沙市天心区伊莱克斯大道由南往北行驶至水电八局基地路段时被在该处执勤的长沙市公安局交通警察支队民警检查，经现场酒精吹气检测，测试结果显示其血液中乙醇含量为195毫克／100毫升，随即被告人莫新国被交警带至湖南省融城医院抽取血样，并将血样送至长沙市公安局物证鉴定所检验，经检验，其血液中乙醇含量为201.1毫克／100毫升。2009年11月15日，被告人莫新国经长沙市残疾人联合会审核为精神残疾人。2018年5月28日，经湖南省芙蓉司法鉴定中心鉴定，被告人莫新国作案时处于普通醉酒状态，实施危害行为时有完全刑事责任能力。2018年1月30日，被告人莫新国主动到公安机关投案，其归案后如实供述了自己的罪行。\"\n",
    "\n",
    "example_candidate = \" 夏邑县人民检察院指控： 2018年5月14日16时12分许，被告人王某某酒后驾驶豫N×××××白色小型轿车，沿夏邑县X019县道由西向东行驶至夏邑县车站镇程大庄村时，被夏邑县交警大队执勤民警当场查获。经现场对王某某进行呼气式酒精含量检测，检测结果为85mg／100ml。后抽血鉴定，王某某静脉血液中乙醇含量为102.97mg／100ml，属醉酒驾驶机动车。 针对上述指控，公诉机关当庭宣读并出示了：1、被告人常住人口基本信息、驾驶人及车辆信息查询；2、（2017）苏0583刑初1140号刑事判决书；3、查获经过；4、酒精呼吸测试单；5、强制措施凭证；6、当事人血样提取登记表；7、商丘普济法医临床司法鉴定所血样检验报告；8、被告人王某某供述等证据。 公诉机关认为，被告人王某某作为具有完全刑事责任能力的成年人，明知饮酒后不允许驾驶机动车辆，仍然违反交通运输管理法规，醉酒状态下驾驶机动车在道路上行驶，其行为触犯了《中华人民共和国刑法》第一百三十三条之一的规定，犯罪事实清楚，证据确实充分，应当以危险驾驶罪追究其刑事责任。被告人在缓刑考验期内又犯新罪，应当撤销缓刑，对新犯的罪作出判决，数罪并罚。提起公诉，请依法判处。 被告人王某某对公诉机关指控的犯罪事实及罪名无异议。 辩护人认为，被告人血液酒精含量较低，没有发生危害后果，虽属醉酒驾驶机动车，但情节显著轻微，应不予定罪处罚。 经审理查明的犯罪事实与公诉机关指控一致，且有下列证据予以证实： 1、被告人常住人口基本信息、驾驶人及机动车信息查询，证明被告人王某某的出生日期及家庭住址，系完全刑事责任年龄人，准驾车型C1，系车主。 2、（2017）苏0583刑初1140号刑事判决书，证明被告人王某某因犯非法拘禁罪于2017年8月9日被江苏省昆山市人民法院判处有期徒刑六个月，缓刑一年。 3、查获经过，证明2018年5月14日16时12分许，王某某酒后驾驶豫N×××××号小型轿车，沿夏邑县X019县道由西向东行驶至夏邑县车站镇程大庄村时，被夏邑县交警大队执勤民警当场查获。经现场对王某某进行呼气式酒精含量检测，检测结果为85mg／100ml。随后把王某某带至夏邑县交警大队。 4、强制措施凭证，证明案发后强制检验王某某血液、尿样。 5、酒精呼吸结果单，证明现场对王某某进行酒精测试，酒精含量为85.0mg／100ml。 6、血样提取登记表，证明2018年5月14日16时40分，交警大队民警带被告人到夏邑县红十字医院提取血样的情况。 7、商丘普济法医临床司法鉴定所血样检验报告，证明经抽取王某某静脉血液检验，血液中乙醇含量为102.97mg／100ml。 8、被告人王某某的供述，证明2018年5月14日16时许，其饮酒后驾驶机动车被民警查获，现场使用呼气式酒精检测仪进行检测，结果为85.0mg／100ml。 上述证据，经庭审举证、质证，证据来源清楚，收集程序合法，能够证明案件事实，本院予以确认。 \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018年5月14日16时12分许，被告人王某某酒后驾驶豫N×××××白色小型轿车，沿夏邑县X019县道由西向东行驶至夏邑县车站镇程大庄村时，被夏邑县交警大队执勤民警当场查获。查获经过，证明2018年5月14日16时12分许，王某某酒后驾驶豫N×××××号小型轿车，沿夏邑县X019县道由西向东行驶至夏邑县车站镇程大庄村时，被夏邑县交警大队执勤民警当场查获。血样提取登记表，证明2018年5月14日16时40分，交警大队民警带被告人到夏邑县红十字医院提取血样的情况。被告人王某某的供述，证明2018年5月14日16时许，其饮酒后驾驶机动车被民警查获，现场使用呼气式酒精检测仪进行检测，结果为85.0mg／100ml。商丘普济法医临床司法鉴定所血样检验报告，证明经抽取王某某静脉血液检验，血液中乙醇含量为102.97mg／100ml。后抽血鉴定，王某某静脉血液中乙醇含量为102.97mg／100ml，属醉酒驾驶机动车。（2017）苏0583刑初1140号刑事判决书，证明被告人王某某因犯非法拘禁罪于2017年8月9日被江苏省昆山市人民法院判处有期徒刑六个月，缓刑一年。辩护人认为，被告人血液酒精含量较低，没有发生危害后果，虽属醉酒驾驶机动车，但情节显著轻微，应不予定罪处罚。经现场对王某某进行呼气式酒精含量检测，检测结果为85mg／100ml。商丘普济法医临床司法鉴定所血样检验报告；酒精呼吸结果单，证明现场对王某某进行酒精测试，酒精含量为85.0mg／100ml。公诉机关认为，被告人王某某作为具有完全刑事责任能力的成年人，明知饮酒后不允许驾驶机动车辆，仍然违反交通运输管理法规，醉酒状态下驾驶机动车在道路上行驶，其行为触犯了《中华人民共和国刑法》第一百三十三条之一的规定，犯罪事实清楚，证据确实充分，应当以危险驾驶罪追究其刑事责任。被告人王某某供述等证据。强制措施凭证，证明案发后强制检验王某某血液、驾驶人及机动车信息查询，证明被告人王某某的出生日期及家庭住址，系完全刑事责任年龄人，准驾车型C1，系车主。被告人常住人口基本信息、酒精呼吸测试单；当事人血样提取登记表；被告人王某某对公诉机关指控的犯罪事实及罪名无异议。被告人在缓刑考验期内又犯新罪，应当撤销缓刑，对新犯的罪作出判决，数罪并罚。随后把王某某带至夏邑县交警大队。驾驶人及车辆信息查询；'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cut_words(sentence):\n",
    "    words = jieba.cut(sentence, cut_all=False)\n",
    "    tem = \" \".join(words).split()\n",
    "    return [i for i in tem if not i in stopwords]\n",
    "\n",
    "\n",
    "def rerank_sentences(query_words, candidate):\n",
    "    candidate_sentences = list(split_sentence(candidate))\n",
    "    corpus = [cut_words(s) for s in candidate_sentences]\n",
    "    bm25Model = bm25.BM25(corpus)\n",
    "    sentence_scores = np.array(bm25Model.get_scores(query_words))\n",
    "    filtered_candidate_sentences = [sent for sent, score in zip(\n",
    "        candidate_sentences, sentence_scores) if score > 0]\n",
    "    filtered_sentence_scores = sentence_scores[sentence_scores > 0]\n",
    "    reranked_sentences = [filtered_candidate_sentences[i]\n",
    "                          for i in filtered_sentence_scores.argsort().tolist()[::-1]]\n",
    "    uniqued_reranked_sentences = list(unique_sentences(reranked_sentences))\n",
    "    return ''.join(uniqued_reranked_sentences)\n",
    "\n",
    "\n",
    "rerank_sentences(cut_words(example_query), example_candidate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 95/197 [05:20<04:55,  2.89s/it]"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data_path, has_label=False):\n",
    "    query_path = osp.join(data_path, 'query.json')\n",
    "    all_candidates_path = osp.join(data_path, 'candidates')\n",
    "    if has_label:\n",
    "        label_path = osp.join(data_path, 'label_top30_dict.json')\n",
    "        label = json.load(open(label_path))\n",
    "        labels = []\n",
    "    edges, inputs, query_ridxs, node_graph_ids, edge_graph_ids, candidate_ridxs = [\n",
    "    ], [], [], [], [], []\n",
    "    with open(query_path) as f:\n",
    "        query_lines = f.readlines()\n",
    "    for query_line in tqdm(query_lines):\n",
    "        query_line = query_line.strip()\n",
    "        query_dict = json.loads(query_line)\n",
    "        input_str = \"[SEP]\".join(query_dict['crime']) + \\\n",
    "            \"[SEP]\"+query_dict['q']\n",
    "        query_words = cut_words(query_dict['q'])\n",
    "        tokenized_inputs = tokenizer(input_str, return_tensors=\"pt\")\n",
    "        query_idx = len(inputs)\n",
    "        inputs.append(tokenized_inputs)\n",
    "        node_graph_ids.append(len(query_ridxs))\n",
    "        query_ridxs.append(query_dict['ridx'])\n",
    "        query_ridx = str(query_dict['ridx'])\n",
    "        candidates_path = osp.join(all_candidates_path, query_ridx)\n",
    "        for candidate in os.listdir(candidates_path):\n",
    "            candidate_ridx = candidate[:-5]\n",
    "            candidate_path = osp.join(candidates_path, candidate)\n",
    "            candidate_dict = json.load(open(candidate_path))\n",
    "            all_text = ''.join(candidate_dict.values())\n",
    "            crime_name = crime_pattern.search(all_text)\n",
    "            if crime_name is None:\n",
    "                crime_name = ''\n",
    "            else:\n",
    "                crime_name = crime_name.group(1) + '罪'\n",
    "            candidate_text = rerank_sentences(\n",
    "                query_words, candidate_dict['ajjbqk'])\n",
    "            candidate_text = '[SEP]'.join(\n",
    "                [crime_name, candidate_text])\n",
    "            tokenized_candidate = tokenizer(\n",
    "                candidate_text, return_tensors=\"pt\")\n",
    "            candidate_idx = len(inputs)\n",
    "            inputs.append(tokenized_candidate)\n",
    "            node_graph_ids.append(node_graph_ids[-1])\n",
    "            edge_graph_ids.append(node_graph_ids[-1])\n",
    "            edges.append([query_idx, candidate_idx])\n",
    "            candidate_ridxs.append(int(candidate_ridx))\n",
    "            if has_label:\n",
    "                if candidate_ridx in label[query_ridx]:\n",
    "                    labels.append(label[query_ridx][candidate_ridx])\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "    if has_label:\n",
    "        return inputs, edges, query_ridxs, node_graph_ids, edge_graph_ids, candidate_ridxs, labels\n",
    "    return inputs, edges, query_ridxs, node_graph_ids, edge_graph_ids, candidate_ridxs\n",
    "\n",
    "\n",
    "train_path = '../data/origin/train'\n",
    "train_inputs, train_edges, train_query_ridxs, train_node_graph_ids, train_edge_graph_ids, train_candidate_ridxs, train_labels = preprocess_data(\n",
    "    train_path, has_label=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(processed_path, edges, inputs, query_ridxs, node_graph_ids, edge_graph_ids, candidate_ridxs, labels=None):\n",
    "    torch.save(inputs, osp.join(processed_path, 'inputs.pt'))\n",
    "    torch.save(edges, osp.join(processed_path, 'edges.pt'))\n",
    "    torch.save(query_ridxs, osp.join(processed_path, 'query_ridxs.pt'))\n",
    "    torch.save(candidate_ridxs, osp.join(processed_path, 'candidate_ridxs.pt'))\n",
    "    torch.save(node_graph_ids, osp.join(processed_path, 'node_graph_ids.pt'))\n",
    "    torch.save(edge_graph_ids, osp.join(processed_path, 'edge_graph_ids.pt'))\n",
    "    if labels is not None:\n",
    "        torch.save(labels, osp.join(processed_path, 'labels.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_path = '../data/bm25/train/processed'\n",
    "os.makedirs(train_processed_path, exist_ok=True)\n",
    "save(train_processed_path, train_edges, train_inputs, train_query_ridxs,\n",
    "     train_node_graph_ids, train_edge_graph_ids, train_candidate_ridxs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '../data/origin/test'\n",
    "test_inputs, test_edges, test_query_ridxs, test_node_graph_ids, test_edge_graph_ids, test_candidate_ridxs = preprocess_data(\n",
    "    test_path, has_label=False)\n",
    "test_processed_path = '../data/bm25/test/processed'\n",
    "os.makedirs(test_processed_path, exist_ok=True)\n",
    "save(test_processed_path, test_edges, test_inputs, test_query_ridxs,\n",
    "     test_node_graph_ids, test_edge_graph_ids, test_candidate_ridxs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3db371a07bed52793c8840e411d9d35d61e1cfd36a2896481af3a875f3ddc4b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('search')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
